{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam, RMSprop, SGD\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, x,y):\n",
        "    scale = StandardScaler()\n",
        "    X_s = scale.fit_transform(x)\n",
        "    x = torch.from_numpy(X_s.astype(np.float32))\n",
        "    y = torch.from_numpy(y.astype(np.float32))\n",
        "    self._base_datasets = x,y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self._base_datasets[0].size(0)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "      return tuple(base_dataset[idx] for base_dataset in self._base_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MyNet(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "      super(MyNet, self).__init__()\n",
        "      self.block_1 = nn.Sequential(\n",
        "          nn.Linear(in_features=8, out_features=100, bias=True),\n",
        "          nn.Dropout(0.1),\n",
        "          nn.BatchNorm1d(100),\n",
        "          nn.ReLU())\n",
        "      self.block_2 = nn.Sequential(\n",
        "          nn.Linear(in_features=100, out_features=100, bias=True),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(100),\n",
        "          nn.ReLU())\n",
        "      self.block_3 = nn.Sequential(\n",
        "          nn.Linear(in_features=100, out_features=60, bias=True),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(60),\n",
        "          nn.ReLU())\n",
        "      self.block_4 = nn.Sequential(\n",
        "          nn.Linear(in_features=60, out_features=30),\n",
        "          nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(30),\n",
        "          nn.ReLU())\n",
        "      self.predict = nn.Sequential(\n",
        "          nn.Linear(in_features=30, out_features=1, bias=True),\n",
        "          nn.BatchNorm1d(1),\n",
        "          nn.ReLU())\n",
        "  \n",
        "  def forward(self, inp):\n",
        "    out = self.block_1(inp)\n",
        "    out = self.block_2(out)\n",
        "    out = self.block_3(out)\n",
        "    out = self.block_4(out)\n",
        "    out = self.predict(out)\n",
        "    return out[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(X_train, y_train)\n",
        "test_dataset = MyDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=0, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = MyNet()\n",
        "optimizer = Adam(net.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_loop(train_loader, test_loader, net, optimizer):\n",
        "  loss_fn = nn.MSELoss()\n",
        "  best_acc = {'train': None, 'test': None}\n",
        "  net.train()\n",
        "  for epoch in range(10):\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        \n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0 or (i + 1) == len(train_loader):    # печатаем каждые 150 mini-batches\n",
        "            net.eval()\n",
        "\n",
        "            test_loss, test_running_total, test_loss  = 0.0, 0.0, 0.0\n",
        "            for y, (out_test, lbl_test) in enumerate(test_loader):\n",
        "                test_outputs = net(out_test)\n",
        "                test_loss += loss_fn(test_outputs, lbl_test)\n",
        "                test_running_total += len(lbl_test)\n",
        "            \n",
        "            res_loss_train = running_loss / running_items\n",
        "            res_loss_test = test_loss / test_running_total\n",
        "            \n",
        "            if best_acc['train'] is None or res_loss_train < best_acc['train']:\n",
        "              best_acc['train'] = res_loss_train\n",
        "            \n",
        "            if best_acc['test'] is None or res_loss_test < best_acc['test']:\n",
        "              best_acc['test'] = res_loss_train\n",
        "\n",
        "            print(f'Epoch [{epoch + 1}/{10}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {res_loss_train:.3f}. '\\\n",
        "                  f'Test acc: {res_loss_test:.3f}.')\n",
        "            \n",
        "            running_loss, running_items = 0.0, 0.0\n",
        "            net.train()       \n",
        "  print(f\"Best acc train: {best_acc['train']:.3f}. Best acc test: {best_acc['test']:.3f}\")\n",
        "  print('Training is finished!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.059. Test acc: 0.088.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.026. Test acc: 0.017.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.011. Test acc: 0.015.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.008. Test acc: 0.015.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.009. Test acc: 0.028.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.008. Test acc: 0.054.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.009. Test acc: 0.054.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.008. Test acc: 0.044.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.007. Test acc: 0.025.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.007. Test acc: 0.025.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.007. Test acc: 0.012.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.007. Test acc: 0.032.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.005. Test acc: 0.033.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.007. Test acc: 0.023.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.007. Test acc: 0.014.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.008. Test acc: 0.015.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.007. Test acc: 0.047.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.007. Test acc: 0.010.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.009. Test acc: 0.011.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.006. Test acc: 0.062.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.004. Test acc: 0.062.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.006. Test acc: 0.038.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.006. Test acc: 0.039.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.006. Test acc: 0.032.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.006. Test acc: 0.034.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.006. Test acc: 0.028.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.006. Test acc: 0.010.\n",
            "Best acc train: 0.004. Best acc test: 0.007\n",
            "Training is finished!\n",
            "CPU times: total: 1min 17s\n",
            "Wall time: 57.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = MyNet()\n",
        "optimizer = RMSprop(net.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.074. Test acc: 0.088.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.015. Test acc: 0.028.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.009. Test acc: 0.015.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.008. Test acc: 0.015.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.008. Test acc: 0.049.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.007. Test acc: 0.033.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.009. Test acc: 0.024.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.008. Test acc: 0.012.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.007. Test acc: 0.044.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.006. Test acc: 0.049.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.007. Test acc: 0.012.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.007. Test acc: 0.030.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.005. Test acc: 0.027.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.007. Test acc: 0.053.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.007. Test acc: 0.009.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.005. Test acc: 0.008.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.006. Test acc: 0.016.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.005. Test acc: 0.008.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.006. Test acc: 0.039.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.005. Test acc: 0.038.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.005. Test acc: 0.008.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.006. Test acc: 0.040.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.004. Test acc: 0.009.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.006. Test acc: 0.021.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.006. Test acc: 0.031.\n",
            "Best acc train: 0.004. Best acc test: 0.005\n",
            "Training is finished!\n",
            "CPU times: total: 1min 5s\n",
            "Wall time: 49 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = MyNet()\n",
        "optimizer = SGD(net.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.051. Test acc: 0.082.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.024. Test acc: 0.011.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.012. Test acc: 0.009.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.011. Test acc: 0.009.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.010. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.010. Test acc: 0.008.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.010. Test acc: 0.008.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.009. Test acc: 0.008.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.009. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.008. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.008. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.007. Test acc: 0.008.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.009. Test acc: 0.008.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.008. Test acc: 0.018.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.007. Test acc: 0.009.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.005. Test acc: 0.010.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.007. Test acc: 0.018.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.007. Test acc: 0.013.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.008. Test acc: 0.013.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.007. Test acc: 0.027.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.007. Test acc: 0.028.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.007. Test acc: 0.030.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.007. Test acc: 0.012.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.009. Test acc: 0.012.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.007. Test acc: 0.025.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.007. Test acc: 0.030.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.007. Test acc: 0.030.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.007. Test acc: 0.012.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.007. Test acc: 0.019.\n",
            "Best acc train: 0.005. Best acc test: 0.007\n",
            "Training is finished!\n",
            "CPU times: total: 54.5 s\n",
            "Wall time: 38.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RMSprop проявил себя лучшим образом , как ни странно , хотя считается что Adam лучше , так как в нем учитывается и \n",
        "идея накопления движения и идея более слабого обновления весов для типичных признаков."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
